<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>SAR图像变化检测深度学习研究方法 | 魔法使いの秘密基地</title><meta name="keywords" content="归纳总结"><meta name="author" content="adventurer-w"><meta name="copyright" content="adventurer-w"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="概述一般方法 第一步，在进行变化检测之前需要对两幅图像进行几何校正、辐射校正以及去噪等预处理操作。  几何校正是指SAR成像过程中，由于传感器姿态、地球旋转等条件的影响会使原始图像上地物的特征与其对应的地面地物的特征发生几何畸变， 所以在变化检测之前需要对图像执行几何校正操作。 辐射校正是指图像在获取、传输过程中会发生辐射失真的现象，因此在图像预处理的过程中有必要进行辐射校正。 图像去噪是指SAR">
<meta property="og:type" content="article">
<meta property="og:title" content="SAR图像变化检测深度学习研究方法">
<meta property="og:url" content="http://example.com/2023/02/01/SAR%20Change%20Detection/index.html">
<meta property="og:site_name" content="魔法使いの秘密基地">
<meta property="og:description" content="概述一般方法 第一步，在进行变化检测之前需要对两幅图像进行几何校正、辐射校正以及去噪等预处理操作。  几何校正是指SAR成像过程中，由于传感器姿态、地球旋转等条件的影响会使原始图像上地物的特征与其对应的地面地物的特征发生几何畸变， 所以在变化检测之前需要对图像执行几何校正操作。 辐射校正是指图像在获取、传输过程中会发生辐射失真的现象，因此在图像预处理的过程中有必要进行辐射校正。 图像去噪是指SAR">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A3E5572F-5538-46C2-B4FD-ECC60C0B90E5_1_105_c.jpeg">
<meta property="article:published_time" content="2023-02-01T14:56:11.000Z">
<meta property="article:modified_time" content="2023-05-15T08:39:52.535Z">
<meta property="article:author" content="adventurer-w">
<meta property="article:tag" content="归纳总结">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A3E5572F-5538-46C2-B4FD-ECC60C0B90E5_1_105_c.jpeg"><link rel="shortcut icon" href="/favicon.png"><link rel="canonical" href="http://example.com/2023/02/01/SAR%20Change%20Detection/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'SAR图像变化检测深度学习研究方法',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-05-15 16:39:52'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/iconfont.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/72805526.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">80</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/bilibili/"><i class="fa-fw fas fa-heart"></i><span> 追番</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A3E5572F-5538-46C2-B4FD-ECC60C0B90E5_1_105_c.jpeg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">魔法使いの秘密基地</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/bilibili/"><i class="fa-fw fas fa-heart"></i><span> 追番</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">SAR图像变化检测深度学习研究方法</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-02-01T14:56:11.000Z" title="发表于 2023-02-01 22:56:11">2023-02-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2023-05-15T08:39:52.535Z" title="更新于 2023-05-15 16:39:52">2023-05-15</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="SAR图像变化检测深度学习研究方法"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><h2 id="一般方法"><a href="#一般方法" class="headerlink" title="一般方法"></a>一般方法</h2><p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-01%2001.19.04.png" alt="截屏2023-02-01 01.19.04"></p>
<p>第一步，在进行变化检测之前需要对两幅图像进行几何校正、辐射校正以及去噪<br>等预处理操作。</p>
<ul>
<li>几何校正是指SAR成像过程中，由于传感器姿态、地球旋转等条件的影响会使原始图像上地物的特征与其对应的地面地物的特征发生几何畸变， 所以在变化检测之前需要对图像执行几何校正操作。</li>
<li>辐射校正是指图像在获取、传输过程中会发生辐射失真的现象，因此在图像预处理的过程中有必要进行辐射校正。</li>
<li>图像去噪是指SAR传感器在成像过程中会被相干斑噪声干扰，导致获取的图像不能准 确而真实的反映出地物信息，故在SAR图像变化检测之前有必要对相干斑噪声进行滤除。</li>
</ul>
<p>第二步，生成差异图是指对两幅SAR图像进行某种操作从而生成为一幅图像 的过程。值得注意的是生成差异图这一步骤在SAR图像变化检测中并不是不可或缺的（该步骤表示为虚线框），经过近年来的研究可知，变化信息可以通过直接对预处理后的图像进行操作来获得。</p>
<p>第三步，采用变化检测算法对差异图或预处理之后的图像以有监督或无监督的方式进行分类，进而得到变化检测结果图</p>
<h2 id="评价指标"><a href="#评价指标" class="headerlink" title="评价指标"></a>评价指标</h2><p>假设，在变化检测结果图中，实际发生变化但检测为未变化的像素点数为Cu， 实际未发生变化但检测为变化的像素点数为Uc，实际未发生变化且检测为未变化的像素点数为Uu，实际发生变化且检测为变化的像素点数为Cc</p>
<p>漏检数False Negatives，FN = Cu</p>
<p>错检数（False Positives，FP = Uc</p>
<p>总错误数（Overall Errors， OE = FN+FP</p>
<p>正确检测率（Percentage Correct Classification，PCC = (Uu+Cc)/(Uu+Cc+Cu+Uc)</p>
<p>Kappa系数Kappa Coefficient，KC = (PCC - PRE)/(1-PRE)</p>
<p>其中</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-01%2001.34.08.png" alt="截屏2023-02-01 01.34.08" style="zoom:50%;" /></p>
<h2 id="目前存在的问题"><a href="#目前存在的问题" class="headerlink" title="目前存在的问题"></a>目前存在的问题</h2><p><strong>SAR图像存在斑点噪声</strong></p>
<p><strong>训练样本有限</strong></p>
<p><strong>获得的伪标签通常存在误差</strong></p>
<p><strong>网络上的固有问题</strong></p>
<p><strong>深度学习方法（至2020年）：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_39932172/article/details/114452418">https://blog.csdn.net/qq_39932172/article/details/114452418</a></strong></p>
<h2 id="基于双路径去噪网络的SAR图像变化检测-2021"><a href="#基于双路径去噪网络的SAR图像变化检测-2021" class="headerlink" title="基于双路径去噪网络的SAR图像变化检测 2021"></a>基于双路径去噪网络的SAR图像变化检测 2021</h2><p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-02%2000.22.43.png" alt="截屏2023-02-02 00.22.43"></p>
<p>一个分支采用随机标签传播来消除预分类中产生的标签噪声。另一个分支是通过叠加多个卷积层来提取浅层和深层特征。最后，将清洁标签和堆叠特征输入分类器，计算最终的变化检测结果</p>
<h4 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h4><p>1)获得的伪标签通常存在误差。</p>
<p>DPDNet的一个分支使用随机标签传播来清除标签噪声。此外，DPDNet的另一个分支用于提取浅层特征和深层特征，然后将它们组合在一起进行分层特征表示。</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-02%2000.21.29.png" alt="截屏2023-02-02 00.21.29" style="zoom:50%;" /></p>
<p>2)基于深度学习的方法在训练阶段非常耗时。缺乏大量可靠样本。</p>
<h4 id="主要贡献"><a href="#主要贡献" class="headerlink" title="主要贡献"></a>主要贡献</h4><ul>
<li>首次尝试同时解决散斑噪声和标签噪声的问题。以往的工作主要集中在散斑噪声方面。然而，标签噪声问题不利于变化检测的性能。所提出的DPDNet可以同时缓解两种噪声，并生成更精确的变化图。</li>
<li>提出了一种新的独特的补丁卷积(DPConv)，它简化了网络结构，加快了训练阶段。从原始图像中提取的patch被用作卷积核，因此参数优化不需要太多的训练样本。</li>
</ul>
<h2 id="基于层注意容噪网络的SAR图像变化检测2022"><a href="#基于层注意容噪网络的SAR图像变化检测2022" class="headerlink" title="基于层注意容噪网络的SAR图像变化检测2022"></a>基于层注意容噪网络的SAR图像变化检测2022</h2><p>提出了一种基于层注意的噪声容忍网络， LANT-Net，它互连卷积层并且对噪声标签不太敏感。</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-03%2000.03.34.png" alt="截屏2023-02-03 00.03.34"></p>
<p>设计了一个用于变化检测的层注意模块，它自适应地对来自不同层的特征进行加权。此外，设计了一个可以有效抑制噪声标签影响的噪声容忍损失函数。它结合了交叉熵 (CE) 损失和平均绝对误差 (MAE)。因此，网络对噪声标签不太敏感并且收敛速度快。</p>
<h4 id="解决的问题-1"><a href="#解决的问题-1" class="headerlink" title="解决的问题"></a>解决的问题</h4><ol>
<li>卷积层之间的特征交互。现有的自注意力增强 CNN 通常在卷积层之后包含一个注意力块，它忽略了多层卷积之间的相互作用。鉴于此，探索卷积层之间的信息流至关重要。</li>
<li>伪标签中涉及的错误。现有的无监督变化检测方法通常使用聚类来生成具有高训练置信度的伪标签。然而，错误参与伪标签限制网络优化。因此，为无监督变化检测任务建立一个噪声容忍模型是至关重要的。</li>
</ol>
<h4 id="主要贡献-1"><a href="#主要贡献-1" class="headerlink" title="主要贡献"></a>主要贡献</h4><ul>
<li><p>提出了一个层注意模块，它利用了多层卷积的相关性。来自不同卷积层的特征相互协作，有效地提高了网络的表示能力。</p>
</li>
<li><p>引入了噪声容忍损失函数来减轻伪标记样本中噪声标签的影响。它使模型对噪声标签不那么敏感，收敛速度快。</p>
</li>
<li>代码开源</li>
</ul>
<h4 id="技术细节"><a href="#技术细节" class="headerlink" title="技术细节"></a>技术细节</h4><p>LANTNet 包括三个组件：预分类模块、卷积干和层注意模块。</p>
<p>预分类使用ratio operator 和 the hierarchical Fuzzy C-Means。将I1、I2、差异图像拼接成3 × R × R，作为输入</p>
<p>卷积干由四个卷积层组成，第一个<code>1*1</code>通道数16，然后三个<code>3*3</code>通道数32，中途生成的特征组合起来，并送入层注意力模块。</p>
<h5 id="层注意模块"><a href="#层注意模块" class="headerlink" title="层注意模块"></a>层注意模块</h5><p>输入X，维度<code>N*C*R*R</code>，N为4（卷积数），C在代码中为32，reshape为<code>N*CRR</code>。</p>
<p>随后，用矩阵乘法将<strong>对角矩阵</strong>W与特征图相乘，来加权来自不同层的特征。（W被初始化为单位矩阵）结果记为X^</p>
<p>然后计算注意力矩阵A。⊗表示矩阵乘法</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-03%2000.33.04.png" alt="截屏2023-02-03 00.33.04" style="zoom:50%;" /></p>
<p>将X^乘以A，reshape为<code>N*C*R*R</code>。与X相加，得到Y。其中φ表示reshape操作。</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-03%2000.35.54.png" alt="截屏2023-02-03 00.35.54" style="zoom:50%;" /></p>
<p>最后通过1*1卷积，FC层，Softmax回归，得到结果。</p>
<h5 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h5><p>{(xi, yi)|1 ≤ i ≤ m} , 其中xi是输入图像补丁，yi是与xi相关的标签，m是样本总数</p>
<p>平均绝对误差 (MAE) Loss，其中f(·)表示网络，ey是one-hot向量</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-03%2000.42.03.png" alt="截屏2023-02-03 00.42.03" style="zoom:50%;" /></p>
<p>交叉熵 (CE) Loss</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-03%2000.42.07.png" alt="截屏2023-02-03 00.42.07" style="zoom:50%;" /></p>
<p>结合起来，α设置为0.1，β设置为0.9</p>
<p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-03%2000.42.13.png" alt="截屏2023-02-03 00.42.13" style="zoom:50%;" /></p>
<h4 id="数据集和评价指标"><a href="#数据集和评价指标" class="headerlink" title="数据集和评价指标"></a>数据集和评价指标</h4><p>第一个数据集为巢湖数据集，大小为384 × 384像素。这颗卫星分别于2020年5月和7月在中国被Sentinel-1传感器捕获。第二个数据集是渥太华数据集，大小为290 × 350像素，分别由Radarsat传感器于1997年5月和8月获取。渥太华数据集显示了受洪水影响的变化地区。第三个数据集是苏兹伯格数据集，由欧洲航天局的Envisat卫星于2011年3月11日和16日捕获。这两张照片都显示了海啸引起的冰架破裂</p>
<p>采用假阳性(FP)、假阴性(FN)、总体误差(OE)、正确分类率(PCC)和Kappa系数(KC)五个常用的评价指标对变化检测性能进行评价。</p>
<h3 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h3><p><a target="_blank" rel="noopener" href="https://github.com/summitgao/LANTNet">https://github.com/summitgao/LANTNet</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io, measure</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> scipy.io <span class="keyword">as</span> sio</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> preclassify <span class="keyword">import</span> del2, srad, dicomp, FCM, hcluster</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span>  Counter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">im1_path = <span class="string">&#x27;Farmland_1.bmp&#x27;</span></span><br><span class="line">im2_path = <span class="string">&#x27;Farmland_2.bmp&#x27;</span></span><br><span class="line">imgt_path = <span class="string">&#x27;Farmland_gt.bmp&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># important parameter</span></span><br><span class="line">patch_size = <span class="number">7</span></span><br></pre></td></tr></table></figure>
<h4 id="定义相关函数"><a href="#定义相关函数" class="headerlink" title="定义相关函数"></a>定义相关函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_normalize</span>(<span class="params">data</span>):</span></span><br><span class="line">    <span class="keyword">import</span> math</span><br><span class="line">    _mean = np.mean(data)</span><br><span class="line">    _std = np.std(data)</span><br><span class="line">    npixel = np.size(data) * <span class="number">1.0</span></span><br><span class="line">    min_stddev = <span class="number">1.0</span> / math.sqrt(npixel)</span><br><span class="line">    <span class="keyword">return</span> (data - _mean) / <span class="built_in">max</span>(_std, min_stddev)</span><br><span class="line"></span><br><span class="line"><span class="comment"># r是margin</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image_padding</span>(<span class="params">data,r</span>):</span> </span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data.shape)==<span class="number">3</span>: <span class="comment"># 三维，第三个维度不需要</span></span><br><span class="line">        data_new=np.lib.pad(data,((r,r),(r,r),(<span class="number">0</span>,<span class="number">0</span>)),<span class="string">&#x27;constant&#x27;</span>,constant_values=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> data_new</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data.shape)==<span class="number">2</span>: <span class="comment"># 二维</span></span><br><span class="line">        data_new=np.lib.pad(data,r,<span class="string">&#x27;constant&#x27;</span>,constant_values=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">return</span> data_new</span><br><span class="line"><span class="comment">#生成自然数数组并打乱</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">arr</span>(<span class="params">length</span>):</span></span><br><span class="line">  arr=np.arange(length-<span class="number">1</span>)</span><br><span class="line">  <span class="comment">#print(arr)</span></span><br><span class="line">  random.shuffle(arr)</span><br><span class="line">  <span class="comment">#print(arr)</span></span><br><span class="line">  <span class="keyword">return</span> arr</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在每个像素周围提取 patch ，然后创建成符合 pytorch 处理的格式</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTrainingCubes</span>(<span class="params">X, y, patch_size</span>):</span></span><br><span class="line">    <span class="comment"># 给 X 做 padding</span></span><br><span class="line">    margin = <span class="built_in">int</span>((patch_size - <span class="number">1</span>) / <span class="number">2</span>)</span><br><span class="line">    zeroPaddedX = image_padding(X, margin)</span><br><span class="line">    <span class="comment"># 把类别 uncertainty 的像素忽略</span></span><br><span class="line">    ele_num1 = np.<span class="built_in">sum</span>(y==<span class="number">1</span>)</span><br><span class="line">    ele_num2 = np.<span class="built_in">sum</span>(y==<span class="number">2</span>) <span class="comment"># 标记为不变和变的个数</span></span><br><span class="line">    <span class="built_in">print</span>(X.shape[<span class="number">2</span>]) </span><br><span class="line">    patchesData_1 = np.zeros( (ele_num1, patch_size, patch_size, X.shape[<span class="number">2</span>]) ) <span class="comment"># 不变，四维</span></span><br><span class="line">    patchesLabels_1 = np.zeros(ele_num1) </span><br><span class="line"></span><br><span class="line">    patchesData_2 = np.zeros((ele_num2, patch_size, patch_size, X.shape[<span class="number">2</span>])) <span class="comment">#变</span></span><br><span class="line">    patchesLabels_2 = np.zeros(ele_num2)</span><br><span class="line"></span><br><span class="line">    patchIndex_1 = <span class="number">0</span> <span class="comment">#记录是第几个不变的patch</span></span><br><span class="line">    patchIndex_2 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(margin, zeroPaddedX.shape[<span class="number">0</span>] - margin):</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(margin, zeroPaddedX.shape[<span class="number">1</span>] - margin):</span><br><span class="line">            <span class="comment"># remove uncertainty pixels</span></span><br><span class="line">            <span class="keyword">if</span> y[r-margin, c-margin] == <span class="number">1</span> : <span class="comment"># 不变</span></span><br><span class="line">                patch_1 = zeroPaddedX[r - margin:r + margin + <span class="number">1</span>, c - margin:c + margin + <span class="number">1</span>] <span class="comment">#(r,c)对应的patch，三维</span></span><br><span class="line">                patchesData_1[patchIndex_1, :, :, :] = patch_1</span><br><span class="line">                patchesLabels_1[patchIndex_1] = y[r-margin, c-margin] <span class="comment"># 1</span></span><br><span class="line">                patchIndex_1 = patchIndex_1 + <span class="number">1</span></span><br><span class="line">            <span class="keyword">elif</span> y[r-margin, c-margin] == <span class="number">2</span> : <span class="comment"># 变</span></span><br><span class="line">                patch_2 = zeroPaddedX[r - margin:r + margin + <span class="number">1</span>, c - margin:c + margin + <span class="number">1</span>]   </span><br><span class="line">                patchesData_2[patchIndex_2, :, :, :] = patch_2</span><br><span class="line">                patchesLabels_2[patchIndex_2] = y[r-margin, c-margin] <span class="comment"># 2</span></span><br><span class="line">                patchIndex_2 = patchIndex_2 + <span class="number">1</span></span><br><span class="line">    patchesLabels_1 = patchesLabels_1-<span class="number">1</span></span><br><span class="line">    patchesLabels_2 = patchesLabels_2-<span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">#调用arr函数打乱数组</span></span><br><span class="line">    arr_1=arr(<span class="built_in">len</span>(patchesData_1))</span><br><span class="line">    arr_2=arr(<span class="built_in">len</span>(patchesData_2))</span><br><span class="line"></span><br><span class="line">    train_len=<span class="number">8000</span>  <span class="comment">#设置训练集样本数</span></span><br><span class="line">    pdata=np.zeros((train_len, patch_size, patch_size, X.shape[<span class="number">2</span>])) <span class="comment"># 8000*7*7*3</span></span><br><span class="line">    plabels = np.zeros(train_len)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7000</span>): <span class="comment"># 不变的各个patch</span></span><br><span class="line">      pdata[i,:,:,:]=patchesData_1[arr_1[i],:,:,:]</span><br><span class="line">      plabels[i]=patchesLabels_1[arr_1[i]]</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7000</span>,train_len):</span><br><span class="line">      pdata[j,:,:,:]=patchesData_2[arr_2[j-<span class="number">7000</span>],:,:,:]</span><br><span class="line">      plabels[j]=patchesLabels_2[arr_2[j-<span class="number">7000</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> pdata, plabels <span class="comment"># 得到数据（len*p*p*3）和标签</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createTestingCubes</span>(<span class="params">X, patch_size</span>):</span></span><br><span class="line">    <span class="comment"># 给 X 做 padding</span></span><br><span class="line">    margin = <span class="built_in">int</span>((patch_size - <span class="number">1</span>) / <span class="number">2</span>)</span><br><span class="line">    zeroPaddedX = image_padding(X, margin)</span><br><span class="line">    patchesData = np.zeros( (X.shape[<span class="number">0</span>]*X.shape[<span class="number">1</span>], patch_size, patch_size, X.shape[<span class="number">2</span>]) )</span><br><span class="line">    patchIndex = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> r <span class="keyword">in</span> <span class="built_in">range</span>(margin, zeroPaddedX.shape[<span class="number">0</span>] - margin):</span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(margin, zeroPaddedX.shape[<span class="number">1</span>] - margin):</span><br><span class="line">            patch = zeroPaddedX[r - margin:r + margin + <span class="number">1</span>, c - margin:c + margin + <span class="number">1</span>]   </span><br><span class="line">            patchesData[patchIndex, :, :, :] = patch</span><br><span class="line">            patchIndex = patchIndex + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> patchesData   </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#  Inputs:  gtImg  = ground truth image</span></span><br><span class="line"><span class="comment">#           tstImg = change map</span></span><br><span class="line"><span class="comment">#  Outputs: FA  = False alarms</span></span><br><span class="line"><span class="comment">#           MA  = Missed alarms</span></span><br><span class="line"><span class="comment">#           OE  = Overall error</span></span><br><span class="line"><span class="comment">#           PCC = Overall accuracy</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">evaluate</span>(<span class="params">gtImg, tstImg</span>):</span></span><br><span class="line">    gtImg[np.where(gtImg&gt;<span class="number">128</span>)] = <span class="number">255</span></span><br><span class="line">    gtImg[np.where(gtImg&lt;<span class="number">128</span>)] = <span class="number">0</span></span><br><span class="line">    tstImg[np.where(tstImg&gt;<span class="number">128</span>)] = <span class="number">255</span></span><br><span class="line">    tstImg[np.where(tstImg&lt;<span class="number">128</span>)] = <span class="number">0</span></span><br><span class="line">    <span class="built_in">print</span>(gtImg.shape)</span><br><span class="line">    [ylen, xlen] = gtImg.shape</span><br><span class="line">    FA = <span class="number">0</span></span><br><span class="line">    MA = <span class="number">0</span></span><br><span class="line">    label_0 = np.<span class="built_in">sum</span>(gtImg==<span class="number">0</span>)</span><br><span class="line">    label_1 = np.<span class="built_in">sum</span>(gtImg==<span class="number">255</span>)</span><br><span class="line">    <span class="built_in">print</span>(label_0)</span><br><span class="line">    <span class="built_in">print</span>(label_1)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,ylen):</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,xlen):</span><br><span class="line">            <span class="keyword">if</span> gtImg[j,i]==<span class="number">0</span> <span class="keyword">and</span> tstImg[j,i]!=<span class="number">0</span> :</span><br><span class="line">                FA = FA+<span class="number">1</span></span><br><span class="line">            <span class="keyword">if</span> gtImg[j,i]!=<span class="number">0</span> <span class="keyword">and</span> tstImg[j,i]==<span class="number">0</span> :</span><br><span class="line">                MA = MA+<span class="number">1</span></span><br><span class="line">  </span><br><span class="line">    OE = FA+MA</span><br><span class="line">    PCC = <span class="number">1</span>-OE/(ylen*xlen)</span><br><span class="line">    PRE=((label_1+FA-MA)*label_1+(label_0+MA-FA)*label_0)/((ylen*xlen)*(ylen*xlen))</span><br><span class="line">    KC=(PCC-PRE)/(<span class="number">1</span>-PRE)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; Change detection results ==&gt;&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; ... ... FP:  &#x27;</span>, FA)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; ... ... FN:  &#x27;</span>, MA)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; ... ... OE:  &#x27;</span>, OE)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; ... ... PCC: &#x27;</span>, <span class="built_in">format</span>(PCC*<span class="number">100</span>, <span class="string">&#x27;.2f&#x27;</span>))</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27; ... ... KC: &#x27;</span>, <span class="built_in">format</span>(KC*<span class="number">100</span>, <span class="string">&#x27;.2f&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">postprocess</span>(<span class="params">res</span>):</span></span><br><span class="line">    res_new = res</span><br><span class="line">    res = measure.label(res, connectivity=<span class="number">2</span>)</span><br><span class="line">    num = res.<span class="built_in">max</span>()</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, num+<span class="number">1</span>):</span><br><span class="line">        idy, idx = np.where(res==i)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(idy) &lt;= <span class="number">20</span>:</span><br><span class="line">            res_new[idy, idx] = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> res_new</span><br></pre></td></tr></table></figure>
<h4 id="得到训练和测试数据"><a href="#得到训练和测试数据" class="headerlink" title="得到训练和测试数据"></a>得到训练和测试数据</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># read image, and then tranform to float32</span></span><br><span class="line"><span class="comment"># 读取Sulzberger</span></span><br><span class="line">im1 = io.imread(im1_path)[:,:,<span class="number">0</span>].astype(np.float32)</span><br><span class="line">im2 = io.imread(im2_path)[:,:,<span class="number">0</span>].astype(np.float32)</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">im_gt = Image.<span class="built_in">open</span>(imgt_path)</span><br><span class="line">im_gt = np.array(im_gt) <span class="comment"># 转换为数组</span></span><br><span class="line">np.unique(im_gt) <span class="comment"># 去重 ，并由小到大排序</span></span><br><span class="line"><span class="built_in">print</span>(im1.shape)</span><br><span class="line"></span><br><span class="line">im_di = dicomp(im1, im2) <span class="comment"># 得到差异图</span></span><br><span class="line">ylen, xlen = im_di.shape</span><br><span class="line">pix_vec = im_di.reshape([ylen*xlen, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 分层FCM聚类</span></span><br><span class="line"><span class="comment"># 在预分类图中，</span></span><br><span class="line"><span class="comment"># 大概率不变的像素标记为1</span></span><br><span class="line"><span class="comment"># 大概率被改变的像素标记为2</span></span><br><span class="line"><span class="comment"># 不确定像素标记为1.5</span></span><br><span class="line">preclassify_lab = hcluster(pix_vec, im_di) <span class="comment"># 291*306，层次聚类</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;... ... hiearchical clustering finished !!!&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mdata = np.zeros([im1.shape[<span class="number">0</span>], im1.shape[<span class="number">1</span>], <span class="number">3</span>], dtype=np.float32)</span><br><span class="line">mdata[:,:,<span class="number">0</span>] = im1</span><br><span class="line">mdata[:,:,<span class="number">1</span>] = im2</span><br><span class="line">mdata[:,:,<span class="number">2</span>] = im_di <span class="comment"># 输入的三个通道，分别为图1、图2、得到的差异图</span></span><br><span class="line"></span><br><span class="line">mlabel = preclassify_lab <span class="comment"># 聚类得到的lable（无监督）</span></span><br><span class="line"></span><br><span class="line">x_train, y_train = createTrainingCubes(mdata, mlabel, patch_size) <span class="comment">#(8000,7,7,3)</span></span><br><span class="line">x_train = x_train.transpose(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>) <span class="comment"># 8000,3,7,7</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;... x train shape: &#x27;</span>, x_train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;... y train shape: &#x27;</span>, y_train.shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x_test = createTestingCubes(mdata, patch_size)</span><br><span class="line">x_test = x_test.transpose(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;... x test shape: &#x27;</span>, x_test.shape)</span><br></pre></td></tr></table></figure>
<h4 id="得到train-loader"><a href="#得到train-loader" class="headerlink" title="得到train_loader"></a>得到train_loader</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot; Training dataset&quot;&quot;&quot;</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TrainDS</span>(<span class="params">torch.utils.data.Dataset</span>):</span> </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        self.<span class="built_in">len</span> = x_train.shape[<span class="number">0</span>] <span class="comment"># 8000</span></span><br><span class="line">        self.x_data = torch.FloatTensor(x_train)</span><br><span class="line">        self.y_data = torch.LongTensor(y_train)        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, index</span>):</span></span><br><span class="line">        <span class="comment"># 根据索引返回数据和对应的标签</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">#x=torch.FloatTensor(data_rotate(self.x_data[index].cpu().numpy()))</span></span><br><span class="line">        <span class="comment">#y=torch.FloatTensor(gasuss_noise(self.y_data[index]))</span></span><br><span class="line">        <span class="comment">#x=torch.FloatTensor(datarotate(self.x_data[index]))</span></span><br><span class="line">        <span class="comment">#return x,self.y_data[index]</span></span><br><span class="line">        <span class="keyword">return</span> self.x_data[index], self.y_data[index]</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span> </span><br><span class="line">        <span class="comment"># 返回文件数据的数目</span></span><br><span class="line">        <span class="keyword">return</span> self.<span class="built_in">len</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 trainloader 和 testloader</span></span><br><span class="line">trainset = TrainDS()</span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<h4 id="层注意力"><a href="#层注意力" class="headerlink" title="层注意力"></a>层注意力</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 层注意力</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LayerAttention</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, N</span>):</span> <span class="comment"># N = 4</span></span><br><span class="line">      <span class="built_in">super</span>(LayerAttention, self).__init__()</span><br><span class="line">      self.N = N </span><br><span class="line">      self.weight = nn.Parameter(torch.eye(self.N,requires_grad=<span class="literal">True</span>)) <span class="comment"># 对角阵</span></span><br><span class="line">      self.softmax  = nn.Softmax(dim=-<span class="number">1</span>)</span><br><span class="line">      </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self,x</span>):</span></span><br><span class="line">      <span class="comment"># B x N x C x H x W</span></span><br><span class="line">      B, N, C, H, W = x.size()</span><br><span class="line">      group_mat = x.view(B, N, -<span class="number">1</span>) <span class="comment"># B*N*CHW 128*4*1568(32*7*7)</span></span><br><span class="line"></span><br><span class="line">      <span class="comment"># 只更新权重矩阵对角线上的元素</span></span><br><span class="line">      gradient_mask = torch.zeros(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">      gradient_mask[<span class="number">0</span>, <span class="number">0</span>] = <span class="number">1.0</span></span><br><span class="line">      gradient_mask[<span class="number">1</span>, <span class="number">1</span>] = <span class="number">1.0</span></span><br><span class="line">      gradient_mask[<span class="number">2</span>, <span class="number">2</span>] = <span class="number">1.0</span></span><br><span class="line">      gradient_mask[<span class="number">3</span>, <span class="number">3</span>] = <span class="number">1.0</span></span><br><span class="line">      device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">      gradient_mask = gradient_mask.to(device) <span class="comment"># 将tensor转移到cuda上,否则报错Expected all tensors to be on the same device（but cpu和cuda:0）</span></span><br><span class="line">      self.weight.register_hook(<span class="keyword">lambda</span> grad: grad.mul_(gradient_mask))</span><br><span class="line">      </span><br><span class="line">      weight = self.weight.unsqueeze(<span class="number">0</span>).repeat([B,<span class="number">1</span>,<span class="number">1</span>])</span><br><span class="line">      reweight = torch.bmm(weight, group_mat) <span class="comment"># 矩阵乘法</span></span><br><span class="line">      <span class="comment"># 进行转置</span></span><br><span class="line">      reweight_trans = reweight.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">      weight_tmp = torch.bmm(reweight,reweight_trans)</span><br><span class="line">      weight_tmp = torch.<span class="built_in">max</span>(weight_tmp, -<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">0</span>].expand_as(weight_tmp)-weight_tmp <span class="comment"># 让原矩阵的每一行最大值减去相应行的数</span></span><br><span class="line">      attention_weight = self.softmax(weight_tmp)</span><br><span class="line"></span><br><span class="line">      out = torch.bmm(attention_weight,reweight)</span><br><span class="line">      out = out.view(B, N, C, H, W)</span><br><span class="line"></span><br><span class="line">      out = out + x</span><br><span class="line">      out = out.view(B, -<span class="number">1</span>, H, W)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h4 id="Loss"><a href="#Loss" class="headerlink" title="Loss"></a>Loss</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 噪声鲁棒的损失函数</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Loss</span>(<span class="params">torch.nn.Module</span>):</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, alpha=<span class="number">0.1</span>, beta=<span class="number">0.9</span>, classes=<span class="number">2</span></span>):</span></span><br><span class="line">      <span class="built_in">super</span>(Loss, self).__init__()</span><br><span class="line">      self.device = <span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span></span><br><span class="line">      self.alpha = alpha</span><br><span class="line">      self.beta = beta</span><br><span class="line">      self.classes = classes</span><br><span class="line">      self.ce = torch.nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, pred, labels</span>):</span></span><br><span class="line">      <span class="comment"># CE</span></span><br><span class="line">      ce = self.ce(pred, labels)</span><br><span class="line">      <span class="comment"># MAE</span></span><br><span class="line">      pred = F.softmax(pred, dim=<span class="number">1</span>)</span><br><span class="line">      label_one_hot = torch.nn.functional.one_hot(labels, self.classes).<span class="built_in">float</span>().to(self.device)</span><br><span class="line">      mae = <span class="number">2</span> - <span class="number">2</span> * (torch.<span class="built_in">sum</span>(pred * label_one_hot, dim=<span class="number">1</span>)) <span class="comment"># 点乘的作用就是取pred的对应类别的那个预测概率</span></span><br><span class="line">      <span class="comment"># Loss</span></span><br><span class="line">      loss = self.alpha * ce + self.beta * mae.mean()</span><br><span class="line">      <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>
<h4 id="LANTNet网络"><a href="#LANTNet网络" class="headerlink" title="LANTNet网络"></a>LANTNet网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LANTNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(LANTNet, self).__init__() </span><br><span class="line">        </span><br><span class="line">        inchannel = <span class="number">3</span></span><br><span class="line">        self.conv1 = nn.Conv2d(inchannel, <span class="number">8</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>) </span><br><span class="line">        self.bn1 = nn.BatchNorm2d(<span class="number">8</span>)</span><br><span class="line">        self.conv1_1 = nn.Conv2d(<span class="number">8</span>, <span class="number">32</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>) </span><br><span class="line">        self.bn1_1 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.conv2_1 = nn.Conv2d(<span class="number">8</span>, <span class="number">16</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">        self.bn2_1 = nn.BatchNorm2d(<span class="number">16</span>)</span><br><span class="line">        self.conv2_11 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2_11 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.conv2_2 = nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">        self.bn2_2 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        self.conv2_22 = nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2_22 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2_3 = nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">        self.bn2_3 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line">        self.conv2_33 = nn.Conv2d(<span class="number">32</span>, <span class="number">32</span>, kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>, padding=<span class="number">0</span>, bias=<span class="literal">False</span>)</span><br><span class="line">        self.bn2_33 = nn.BatchNorm2d(<span class="number">32</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        self.lam= LayerAttention(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        self.conv3 = nn.Conv2d(<span class="number">128</span>, <span class="number">4</span>, kernel_size=<span class="number">3</span>, stride=<span class="number">1</span>, padding=<span class="number">1</span>, bias=<span class="literal">True</span>)</span><br><span class="line">        self.bn3 = nn.BatchNorm2d(<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line">        self.linear1=nn.Linear(<span class="number">196</span>, <span class="number">10</span>) </span><br><span class="line">        self.linear2=nn.Linear(<span class="number">10</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line"></span><br><span class="line">        ori_out1 = F.relu(self.bn1(self.conv1(x)))</span><br><span class="line">        m1 = F.relu(self.bn1_1(self.conv1_1(ori_out1)))<span class="comment"># 统一到32个通道上来(以便进行层注意力计算)</span></span><br><span class="line"></span><br><span class="line">        ori_out2 = F.relu(self.bn2_1(self.conv2_1(ori_out1)))</span><br><span class="line">        m2 = F.relu(self.bn2_11(self.conv2_11(ori_out2)))<span class="comment"># 统一到32个通道上来</span></span><br><span class="line"></span><br><span class="line">        ori_out3 = F.relu(self.bn2_2(self.conv2_2(ori_out2)))</span><br><span class="line">        m3 = F.relu(self.bn2_22(self.conv2_22(ori_out3)))<span class="comment"># 统一到32个通道上来</span></span><br><span class="line"></span><br><span class="line">        ori_out4 = F.relu(self.bn2_3(self.conv2_3(ori_out3)))</span><br><span class="line">        m4 = F.relu(self.bn2_33(self.conv2_33(ori_out4)))<span class="comment"># 统一到32个通道上来</span></span><br><span class="line"></span><br><span class="line">        out5 = torch.stack([m1, m2, m3, m4],dim = <span class="number">1</span>) <span class="comment"># 拼接</span></span><br><span class="line">        out5 = self.lam(out5) </span><br><span class="line">        out = F.relu(self.bn3(self.conv3(out5)))</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>) <span class="comment"># 拉直</span></span><br><span class="line">        <span class="comment">#print(out.shape)</span></span><br><span class="line">        out_1 = self.linear1(out)</span><br><span class="line">        out = self.linear2(out_1)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>
<h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用GPU训练，可以在菜单 &quot;代码执行工具&quot; -&gt; &quot;更改运行时类型&quot; 里进行设置</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">istrain = <span class="literal">True</span></span><br><span class="line"><span class="comment"># 网络放到GPU上</span></span><br><span class="line">net =LANTNet().to(device)</span><br><span class="line">criterion = Loss(alpha=<span class="number">0.1</span>, beta=<span class="number">0.9</span>, classes=<span class="number">2</span>).to(device)</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">net.train()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开始训练</span></span><br><span class="line">total_loss = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60</span>):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line"></span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        <span class="comment"># 优化器梯度归零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 正向传播 +　反向传播 + 优化 </span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        total_loss += loss.item()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[Epoch: %d]  [loss avg: %.4f]  [current loss: %.4f]&#x27;</span> %(epoch + <span class="number">1</span>, total_loss/(epoch+<span class="number">1</span>), loss.item()))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>
<h4 id="检验"><a href="#检验" class="headerlink" title="检验"></a>检验</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 逐像素预测类别</span></span><br><span class="line">istrain=<span class="literal">False</span></span><br><span class="line">net.<span class="built_in">eval</span>()</span><br><span class="line">outputs = np.zeros((ylen, xlen))</span><br><span class="line">glo_fin=torch.Tensor([]).cuda()</span><br><span class="line">dct_fin=torch.Tensor([]).cuda()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(ylen):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(xlen):</span><br><span class="line">        img_patch = x_test[i*xlen+j, :, :, :]</span><br><span class="line">        img_patch = img_patch.reshape(<span class="number">1</span>, img_patch.shape[<span class="number">0</span>], img_patch.shape[<span class="number">1</span>], img_patch.shape[<span class="number">2</span>])</span><br><span class="line">        img_patch = torch.FloatTensor(img_patch).to(device)</span><br><span class="line">        prediction = net(img_patch)</span><br><span class="line"></span><br><span class="line">        prediction = np.argmax(prediction.detach().cpu().numpy(), axis=<span class="number">1</span>)</span><br><span class="line">        outputs[i, j] = prediction + <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            </span><br><span class="line">    <span class="keyword">if</span> (i+<span class="number">1</span>) % <span class="number">50</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;... ... row&#x27;</span>, i+<span class="number">1</span>, <span class="string">&#x27; handling ... ...&#x27;</span>)</span><br><span class="line"></span><br><span class="line">outputs = outputs-<span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.imshow(outputs, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">res = outputs*<span class="number">255</span></span><br><span class="line">res = postprocess(res)</span><br><span class="line">evaluate(im_gt, res)</span><br><span class="line">plt.imshow(res, <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="基于双域网络的SAR图像变化检测2022"><a href="#基于双域网络的SAR图像变化检测2022" class="headerlink" title="基于双域网络的SAR图像变化检测2022"></a>基于双域网络的SAR图像变化检测2022</h2><p><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-02-03%2022.17.06.png" alt="截屏2023-02-03 22.17.06"></p>
<p>该网络由两个分支组成:一个是用于捕获多区域特征的空间域分支，一个是用于编码DCT系数的频域分支。在空间域分支中，该网络包含四个MRC模块，能够在保留上下文信息的同时强调中心区域特征。在频域分支中，将输入图像补丁通过DCT转换到频域，然后通过“开关”选择DCT系数的关键分量。</p>
<h4 id="解决的问题-2"><a href="#解决的问题-2" class="headerlink" title="解决的问题"></a>解决的问题</h4><ul>
<li><p>现有的方法主要集中在空间域的特征提取上，对频域的特征提取较少关注。</p>
</li>
<li><p>在patch特征分析中，边缘区域可能引入一些噪声特征。</p>
</li>
</ul>
<h4 id="主要贡献-2"><a href="#主要贡献-2" class="headerlink" title="主要贡献"></a>主要贡献</h4><ul>
<li>第一个引入DCT域的特征来解决SAR图像变化检测问题。利用了频域和空间两方面的特征。因此，可以有效地抑制散斑噪声</li>
<li>提出了一个MRC模块，它联合强调每个图像补丁的中心区域，同时保留上下文信息。对中心区域特征和上下文信息进行自适应组织以完成分类任务。</li>
</ul>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">adventurer-w</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2023/02/01/SAR%20Change%20Detection/">http://example.com/2023/02/01/SAR%20Change%20Detection/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">魔法使いの秘密基地</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%BD%92%E7%BA%B3%E6%80%BB%E7%BB%93/">归纳总结</a></div><div class="post_share"><div class="social-share" data-image="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A3E5572F-5538-46C2-B4FD-ECC60C0B90E5_1_105_c.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/02/11/anime/"><img class="prev-cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/[lab.magiconch.com][One-Last-Image]-1676018174594.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">杂谈100B：动画安利（个人向）</div></div></a></div><div class="next-post pull-right"><a href="/2023/01/09/6DPose-1/"><img class="next-cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A3E5572F-5538-46C2-B4FD-ECC60C0B90E5_1_105_c.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">6D姿态估计-笔记1</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/01/09/6DPose-1/" title="6D姿态估计-笔记1"><img class="cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A3E5572F-5538-46C2-B4FD-ECC60C0B90E5_1_105_c.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-01-09</div><div class="title">6D姿态估计-笔记1</div></div></a></div><div><a href="/2022/09/29/Transformer1/" title="Transformer笔记1 —— BERT"><img class="cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/9F442EA0-F893-45C6-8967-10A3799F6DFC.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-29</div><div class="title">Transformer笔记1 —— BERT</div></div></a></div><div><a href="/2022/09/29/Transformer2/" title="Transformer笔记2 —— VIT"><img class="cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/703C5B20-1C26-4B29-B378-B5B9FD03B485_1_105_c.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-29</div><div class="title">Transformer笔记2 —— VIT</div></div></a></div><div><a href="/2022/09/30/Transformer3/" title="Transformer笔记3——SwinTransformer"><img class="cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/761D60E7-9EB9-4498-9053-86BF95761992_1_102_o.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-30</div><div class="title">Transformer笔记3——SwinTransformer</div></div></a></div><div><a href="/2022/11/23/detection/" title="目标检测相关摘录"><img class="cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/628FBB49-B697-4165-8B49-A59144FB233F_1_102_o.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-11-23</div><div class="title">目标检测相关摘录</div></div></a></div><div><a href="/2022/10/20/mae/" title="自监督——MAE"><img class="cover" src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/DBAC18EC-952B-4B36-B2D9-B9A5F74C90D4.jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-10-20</div><div class="title">自监督——MAE</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/72805526.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">adventurer-w</div><div class="author-info__description">励志好好学习魔法ヾ(=･ω･=)o</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">80</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">16</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">10</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/adventurer-w"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://space.bilibili.com/91422238" target="_blank" title="BiliBili"><i class="iconfont icon-bilibili-line"></i></a><a class="social-icon" href="https://space.bilibili.com/91422238" target="_blank" title="BiliBili"><i class="iconfont icon-weibo"></i></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A6%82%E8%BF%B0"><span class="toc-number">1.</span> <span class="toc-text">概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E8%88%AC%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.</span> <span class="toc-text">一般方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">1.2.</span> <span class="toc-text">评价指标</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E5%89%8D%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.</span> <span class="toc-text">目前存在的问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%8F%8C%E8%B7%AF%E5%BE%84%E5%8E%BB%E5%99%AA%E7%BD%91%E7%BB%9C%E7%9A%84SAR%E5%9B%BE%E5%83%8F%E5%8F%98%E5%8C%96%E6%A3%80%E6%B5%8B-2021"><span class="toc-number">1.4.</span> <span class="toc-text">基于双路径去噪网络的SAR图像变化检测 2021</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.4.0.1.</span> <span class="toc-text">解决的问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE"><span class="toc-number">1.4.0.2.</span> <span class="toc-text">主要贡献</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%B1%82%E6%B3%A8%E6%84%8F%E5%AE%B9%E5%99%AA%E7%BD%91%E7%BB%9C%E7%9A%84SAR%E5%9B%BE%E5%83%8F%E5%8F%98%E5%8C%96%E6%A3%80%E6%B5%8B2022"><span class="toc-number">1.5.</span> <span class="toc-text">基于层注意容噪网络的SAR图像变化检测2022</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98-1"><span class="toc-number">1.5.0.1.</span> <span class="toc-text">解决的问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE-1"><span class="toc-number">1.5.0.2.</span> <span class="toc-text">主要贡献</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82"><span class="toc-number">1.5.0.3.</span> <span class="toc-text">技术细节</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%B1%82%E6%B3%A8%E6%84%8F%E6%A8%A1%E5%9D%97"><span class="toc-number">1.5.0.3.1.</span> <span class="toc-text">层注意模块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.5.0.3.2.</span> <span class="toc-text">损失函数</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%92%8C%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87"><span class="toc-number">1.5.0.4.</span> <span class="toc-text">数据集和评价指标</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.5.1.</span> <span class="toc-text">代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%AE%9A%E4%B9%89%E7%9B%B8%E5%85%B3%E5%87%BD%E6%95%B0"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">定义相关函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%97%E5%88%B0%E8%AE%AD%E7%BB%83%E5%92%8C%E6%B5%8B%E8%AF%95%E6%95%B0%E6%8D%AE"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">得到训练和测试数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BE%97%E5%88%B0train-loader"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">得到train_loader</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%B1%82%E6%B3%A8%E6%84%8F%E5%8A%9B"><span class="toc-number">1.5.1.4.</span> <span class="toc-text">层注意力</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Loss"><span class="toc-number">1.5.1.5.</span> <span class="toc-text">Loss</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#LANTNet%E7%BD%91%E7%BB%9C"><span class="toc-number">1.5.1.6.</span> <span class="toc-text">LANTNet网络</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">1.5.1.7.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A3%80%E9%AA%8C"><span class="toc-number">1.5.1.8.</span> <span class="toc-text">检验</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%8F%8C%E5%9F%9F%E7%BD%91%E7%BB%9C%E7%9A%84SAR%E5%9B%BE%E5%83%8F%E5%8F%98%E5%8C%96%E6%A3%80%E6%B5%8B2022"><span class="toc-number">1.6.</span> <span class="toc-text">基于双域网络的SAR图像变化检测2022</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E7%9A%84%E9%97%AE%E9%A2%98-2"><span class="toc-number">1.6.0.1.</span> <span class="toc-text">解决的问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE-2"><span class="toc-number">1.6.0.2.</span> <span class="toc-text">主要贡献</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2023/05/27/QD-DETR.md/" title="CVPR 2023:Query-Dependent Video Representation for Moment Retrieval and Highlight Detection"><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/412C1CBF-59A3-49FE-88AC-6157AA95C616_1_105_c.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CVPR 2023:Query-Dependent Video Representation for Moment Retrieval and Highlight Detection"/></a><div class="content"><a class="title" href="/2023/05/27/QD-DETR.md/" title="CVPR 2023:Query-Dependent Video Representation for Moment Retrieval and Highlight Detection">CVPR 2023:Query-Dependent Video Representation for Moment Retrieval and Highlight Detection</a><time datetime="2023-05-27T14:56:12.000Z" title="发表于 2023-05-27 22:56:12">2023-05-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/27/VDI/" title="CVPR 2023-Towards Generalisable Video Moment Retrieval:Visual-Dynamic Injection to Image-Text Pre-Training"><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/2BFB88C0-7BD6-4523-8387-8CAFF7EACECA_1_105_c.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="CVPR 2023-Towards Generalisable Video Moment Retrieval:Visual-Dynamic Injection to Image-Text Pre-Training"/></a><div class="content"><a class="title" href="/2023/05/27/VDI/" title="CVPR 2023-Towards Generalisable Video Moment Retrieval:Visual-Dynamic Injection to Image-Text Pre-Training">CVPR 2023-Towards Generalisable Video Moment Retrieval:Visual-Dynamic Injection to Image-Text Pre-Training</a><time datetime="2023-05-27T14:56:11.000Z" title="发表于 2023-05-27 22:56:11">2023-05-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/12/diffusion/" title="万字解读~~~扩散模型和跨模态生成(内含数学推导)"><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/%E6%88%AA%E5%B1%8F2023-05-26%2015.02.42.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="万字解读~~~扩散模型和跨模态生成(内含数学推导)"/></a><div class="content"><a class="title" href="/2023/05/12/diffusion/" title="万字解读~~~扩散模型和跨模态生成(内含数学推导)">万字解读~~~扩散模型和跨模态生成(内含数学推导)</a><time datetime="2023-05-12T14:56:11.000Z" title="发表于 2023-05-12 22:56:11">2023-05-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/05/10/CLIP/" title="万字解读~~~大规模预训练模型在视觉理解中的应用——以CLIP为例"><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A9AF49B6-C7E1-43E6-9E62-7394CA513346.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="万字解读~~~大规模预训练模型在视觉理解中的应用——以CLIP为例"/></a><div class="content"><a class="title" href="/2023/05/10/CLIP/" title="万字解读~~~大规模预训练模型在视觉理解中的应用——以CLIP为例">万字解读~~~大规模预训练模型在视觉理解中的应用——以CLIP为例</a><time datetime="2023-05-10T14:56:11.000Z" title="发表于 2023-05-10 22:56:11">2023-05-10</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/06/lqb66666/" title="python算法复习笔记5(DP,数学)"><img src="https://tuchuang-1308516817.cos.ap-nanjing.myqcloud.com/img/A9CD8212-2784-45D6-9D4E-D39E860755A9_1_105_c.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="python算法复习笔记5(DP,数学)"/></a><div class="content"><a class="title" href="/2023/04/06/lqb66666/" title="python算法复习笔记5(DP,数学)">python算法复习笔记5(DP,数学)</a><time datetime="2023-04-06T11:57:54.000Z" title="发表于 2023-04-06 19:57:54">2023-04-06</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By adventurer-w</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [ ['$','$'], ["\\(","\\)"]],
      tags: 'ams'
    },
    chtml: {
      scale: 1.2
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, ''],
        insertScript: [200, () => {
          document.querySelectorAll('mjx-container:not\([display]\)').forEach(node => {
            const target = node.parentNode
            if (target.nodeName.toLowerCase() === 'li') {
              target.parentNode.classList.add('has-jax')
            } else {
              target.classList.add('has-jax')
            }
          });
        }, '', false]
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typeset()
}</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'WmXbg5ij5vMxwX438aE8YqmW-gzGzoHsz',
      appKey: '1csr0uQv2Nu1k8EmKultS9gQ',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'zh-CN',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
      requiredFields: ["nick,mail"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>